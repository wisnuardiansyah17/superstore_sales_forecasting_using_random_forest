{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import library for visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import library for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the specified file location and display the first few rows\n",
    "dataset_location = \"File Location\"\n",
    "df = pd.read_csv(dataset_location)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Outlier\n",
    "#Plot sales distribution using boxplot\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.boxplot(df.Sales)\n",
    "plt.title('Sales Distribution: Boxplot Analysis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sales distribution\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.hist(df['Sales'], bins=20,color='skyblue',edgecolor='black')\n",
    "plt.title('Sales Distribution')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sales distribution by categories\n",
    "grouped_data = df.groupby('Category')['Sales'].sum().reset_index()\n",
    "labels = grouped_data['Category']\n",
    "sizes = grouped_data['Sales']\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.pie(sizes, labels=labels,autopct='%1.1f%%')\n",
    "plt.title('Sales Distribution by Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot average sales per category\n",
    "data_histogram= df.groupby('Category')['Sales'].mean().reset_index().sort_values(by='Sales', ascending=False)\n",
    "data_histogram = data_histogram.head(3)\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.bar(data_histogram['Category'], data_histogram['Sales'])\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Avarage Sales')\n",
    "plt.title('Average Sales per Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the DataFrame to include only the 'Furniture' category and sort it by 'Sales' in descending order\n",
    "furniture_data=df[df['Category']=='Furniture'].sort_values(by='Sales', ascending=False)\n",
    "\n",
    "#Display summary statistics for the filtered Furniture sales data\n",
    "furniture_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the DataFrame to include only the 'Technology' category and sort it by 'Sales' in descending order\n",
    "technology_data=df[df['Category']=='Technology'].sort_values(by='Sales', ascending=False)\n",
    "\n",
    "#Display summary statistics for the filtered technology sales data\n",
    "technology_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the DataFrame to include only the 'Office Supplies' category and sort it by 'Sales' in descending order\n",
    "office_supplies_data = df[df['Category']=='Office Supplies'].sort_values(by='Sales', ascending=False)\n",
    "\n",
    "#Display summary statistics for the filtered Office Supplies sales data\n",
    "office_supplies_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers in the 'Sales' column by filtering for value between 1 and 470\n",
    "df=df[(df['Sales']>=1)&(df['Sales']<=470)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display basic information about dataset, including data types and non-null counts\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing (null) values in the DataFrame and display the count of null values for each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Duplicate rows in the DataFrame and display the count of duplicate\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in the 'Postal Code' column with 0\n",
    "df['Postal Code'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics for the Data Frame\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sales distribution using boxplot\n",
    "sns.boxplot(y=df['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Order Date' and 'Ship Date' columns to datetime data type\n",
    "# Then, sort the DataFrame based on 'Order Date' in descending order\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
    "df = df.sort_values(by='Order Date', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a new column for day, month, year, week and dayname\n",
    "df['Day'] = (df['Order Date']).dt.day\n",
    "df['Month'] = (df['Order Date']).dt.month\n",
    "df['Year'] = (df['Order Date']).dt.year\n",
    "df['Week'] = (df['Order Date']).dt.isocalendar().week\n",
    "df['Dayname'] = df['Order Date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping months to season\n",
    "season_mapping = {\n",
    "    1: 'Winter',\n",
    "    2: 'Winter',\n",
    "    3: 'Spring',\n",
    "    4: 'Spring',\n",
    "    5: 'Spring',\n",
    "    6: 'Summer',\n",
    "    7: 'Summer',\n",
    "    8: 'Summer',\n",
    "    9: 'Fall',\n",
    "    10: 'Fall',\n",
    "    11: 'Fall',\n",
    "    12: 'Winter'\n",
    "}\n",
    "\n",
    "df[\"Season\"]=df['Month'].map(season_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot yearly sales trends\n",
    "data_group_sales_by_month = df.groupby(['Year','Month'])['Sales'].sum().reset_index().sort_values(by=['Year','Month'])\n",
    "data_group_sales_by_month['YearMonth'] = data_group_sales_by_month['Year'].astype(str) + '-' + data_group_sales_by_month['Month'].astype(str)\n",
    "data_group_sales_by_month['YearMonth'] = pd.to_datetime(data_group_sales_by_month['YearMonth'] + '-1', format='%Y-%m-%d')\n",
    "plt.figure(figsize=(19,8))\n",
    "sns.lineplot(x='YearMonth', y='Sales', data=data_group_sales_by_month)\n",
    "plt.title('Year-to-Year Sales Growth Trends')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sales distribution by product categories\n",
    "grouped_data = df.groupby('Category')['Sales'].sum().reset_index()\n",
    "labels = grouped_data['Category']\n",
    "sizes = grouped_data['Sales']\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.pie(sizes, labels=labels,autopct='%1.1f%%')\n",
    "plt.title('Sales Distribution by Product Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sales distribution by customer segments\n",
    "grouped_data = df.groupby('Segment')['Sales'].sum().reset_index()\n",
    "labels = grouped_data['Segment']\n",
    "sizes = grouped_data['Sales']\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.pie(sizes, labels=labels,autopct='%1.1f%%')\n",
    "plt.title('Sales Distribution by Customer Segments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot top 10 revenue-generating cities\n",
    "top_10_city_based_on_revenue_df=df.groupby('City')['Sales'].sum().reset_index().sort_values(by='Sales', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(26,10))\n",
    "plt.barh(top_10_city_based_on_revenue_df['City'].head(10)[::-1], top_10_city_based_on_revenue_df['Sales'].head(10)[::-1], color='tomato')\n",
    "plt.xlabel('Total Sales')\n",
    "# plt.ylabel('City')\n",
    "plt.title('Top 10 Revenue-Generating Cities')\n",
    "\n",
    "for sales,city in zip(top_10_city_based_on_revenue_df['Sales'].head(10)[::-1], top_10_city_based_on_revenue_df['City'].head(10)[::-1]):\n",
    "    plt.text(sales,city,f'${sales: .2f}',horizontalalignment='left',color='black',fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot shipping methods comparison\n",
    "ship_mode_ranking_based_on_revenue_df = df.groupby('Ship Mode')['Sales'].sum().reset_index().sort_values(by='Sales', ascending=False)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(ship_mode_ranking_based_on_revenue_df['Ship Mode'], ship_mode_ranking_based_on_revenue_df['Sales'], color='tomato')\n",
    "plt.xlabel('Ship Mode')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Shipping Methods Comparison')\n",
    "\n",
    "for k,v in enumerate(ship_mode_ranking_based_on_revenue_df['Sales']):\n",
    "    plt.text(k,v,'$'+str(v), fontsize=12 ,color='black',horizontalalignment='center',verticalalignment='bottom')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot top 10 revenue-generating product\n",
    "top_10_product_df= df.groupby('Product Name')['Sales'].sum().reset_index().sort_values(by='Sales', ascending=False)\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.barh(top_10_product_df['Product Name'].head(10)[::-1], top_10_product_df['Sales'].head(10)[::-1],color='skyblue')\n",
    "plt.xlabel('Total Sales')\n",
    "# plt.ylabel('Total Sales')\n",
    "plt.title('Top 10 Revenue-Generating Product')\n",
    "\n",
    "for sales, product in zip(top_10_product_df['Sales'].head(10)[::-1],top_10_product_df['Product Name'].head(10)[::-1]):\n",
    "     label =f'${sales:.2f}'\n",
    "     plt.text(sales,product, label, horizontalalignment='center',verticalalignment='center',color='black',fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot average daily sales\n",
    "dayname_mean_sales_df = df.groupby('Dayname')['Sales'].mean().reset_index()\n",
    "day_order = pd.DataFrame({\n",
    "    'Dayname': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "    'Day_Order': [0, 1, 2, 3, 4, 5, 6]\n",
    "})\n",
    "\n",
    "dayname_mean_sales_df =dayname_mean_sales_df.merge(day_order, on='Dayname', how='left')\n",
    "\n",
    "dayname_mean_sales_df = dayname_mean_sales_df.sort_values(by='Day_Order', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.bar(dayname_mean_sales_df['Dayname'], dayname_mean_sales_df['Sales'],color='tomato')\n",
    "plt.ylabel('Average Sales')\n",
    "plt.title('Average Daily Sales')\n",
    "\n",
    "for day,sales in zip(dayname_mean_sales_df['Dayname'], dayname_mean_sales_df['Sales']):\n",
    "    label =f'${sales:.2f}'\n",
    "    plt.text(day, sales, label, horizontalalignment='center',verticalalignment='bottom',color='black',fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot seasonal sales analysis\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "seasonal_sales_analysis = df.groupby('Season')['Sales'].sum().reindex(season_order).reset_index()\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.bar(seasonal_sales_analysis['Season'],seasonal_sales_analysis['Sales'], color='tomato')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Seasonal Sales Analysis')\n",
    "\n",
    "for season, sales in zip(seasonal_sales_analysis['Season'],seasonal_sales_analysis['Sales']):\n",
    "    plt.text(season, sales, f'{sales:.2f}', horizontalalignment='center',verticalalignment='bottom',color='black', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Top 10 Sub-Category by revenue\n",
    "data_top_5_sub_category_by_sales = df.groupby('Sub-Category')['Sales'].sum().reset_index().sort_values(by='Sales', ascending=False)\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.bar(data_top_5_sub_category_by_sales['Sub-Category'].head(10), data_top_5_sub_category_by_sales['Sales'].head(10),color='tomato')\n",
    "plt.xlabel('Sub-Category')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Top 10 Revenue-Generating Sub-Categories')\n",
    "\n",
    "for subcategory,sales in zip(data_top_5_sub_category_by_sales['Sub-Category'].head(10), data_top_5_sub_category_by_sales['Sales'].head(10)):\n",
    "    plt.text(subcategory, sales, f'{sales:.2f}',horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Most Valuable Customer\n",
    "loyal_customer_df = df.groupby('Customer Name')['Sales'].sum().reset_index().sort_values(by='Sales',ascending=False)\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.barh(loyal_customer_df['Customer Name'].head(10)[::-1], loyal_customer_df['Sales'].head(10)[::-1], color = 'lightblue')\n",
    "plt.xlabel('Total Spend')\n",
    "# plt.ylabel('Customer Name')\n",
    "plt.title('Most Valuable Customer')\n",
    "\n",
    "for sales, customer in zip(loyal_customer_df['Sales'].head(10)[::-1],loyal_customer_df['Customer Name'].head(10)[::-1]):\n",
    "    plt.text(sales, customer, f'${sales:.2f}', horizontalalignment= 'center', verticalalignment='center',fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Sales Distribution\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df['Sales'], bins=20,color='skyblue',edgecolor='black')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Sales Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_superstore = df[['Day','Week', 'Month','Year','Category','Sales','Region', 'Sub-Category']]\n",
    "numerical_feature=['Day','Week', 'Month','Year','Sales']\n",
    "categorical_feature = ['Category','Region', 'Sub-Category']\n",
    "\n",
    "#encode categorical feature using one-hot encoding\n",
    "encoded_categorical_feature = pd.get_dummies(df_superstore[categorical_feature], drop_first=True)\n",
    "\n",
    "#concatenate the encoded feature with the numerical feature\n",
    "encoded_df_superstore= pd.concat([encoded_categorical_feature, df_superstore[numerical_feature]], axis=1)\n",
    "\n",
    "#Splitting data into feature(X) and target(y)\n",
    "X = encoded_df_superstore.drop('Sales', axis=1)\n",
    "y =encoded_df_superstore['Sales']\n",
    "\n",
    "#Splitting data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the model\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model to your data\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction\n",
    "y_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model using mse\n",
    "mse_RF = mean_squared_error(y_test,y_prediction, squared=False)\n",
    "print('mean squared error:', mse_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model using mae\n",
    "mae_RF = mean_absolute_error(y_test, y_prediction)\n",
    "print('mean absolute error:', mae_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model using rmse\n",
    "rmse_RF = np.sqrt(mse_RF)\n",
    "print('Root Mean Squared Error :', rmse_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Parameter grid for GridSearchCV\n",
    "n_estimators = [100,200,300]\n",
    "max_feature = [10,15,20,26]\n",
    "min_samples_leaf = [100,250,500,1000] \n",
    "max_depth = [10,15,25]\n",
    "param_grid = {'n_estimators': n_estimators,'max_features': max_feature, 'min_samples_leaf': min_samples_leaf,'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,param_grid= param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the best grid parameters\n",
    "print(\"best grid parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a Random Forest model with the best hyperparameters\n",
    "rf_tuning = RandomForestRegressor(\n",
    "    n_estimators=grid_search.best_params_['n_estimators'], \n",
    "    max_features=grid_search.best_params_['max_features'], \n",
    "    min_samples_leaf=grid_search.best_params_['min_samples_leaf'], \n",
    "    max_depth=grid_search.best_params_['max_depth']\n",
    ")\n",
    "\n",
    "rf_tuning.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_prediction_tuning = rf_tuning.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model using mean squared error(mse)\n",
    "mse_RFTuning = mean_squared_error(y_test,y_prediction_tuning, squared=False)\n",
    "print('mean squared error:', mse_RFTuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model using mean absolute error(mae)\n",
    "mae_RFTuning = mean_absolute_error(y_test, y_prediction_tuning)\n",
    "print('mean absolute error:', mae_RFTuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model using root mean squared error(rmse)\n",
    "rmse_RFTuning = np.sqrt(mse_RFTuning)\n",
    "print('Root Mean Squared Errot:', rmse_RFTuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a comparison DataFrame for model evaluation\n",
    "comparison_model_df = pd.DataFrame({\n",
    "    'Model':['Random Forest', 'Random Forest With Hyperparameter Tuning'],\n",
    "    'MSE': [mse_RF,mse_RFTuning],\n",
    "    'MAE': [mae_RF,mae_RFTuning],\n",
    "    'RMSE': [rmse_RF,rmse_RFTuning]\n",
    "})\n",
    "\n",
    "#Display the comparison DataFrame\n",
    "comparison_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING THE MODEL WITH THE FIRST 20 DATA POINTS IN X_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model with the first 20 data points in X_test\n",
    "X_test_subset = X_test.head(20)\n",
    "prediction_final = rf_tuning.predict(X_test_subset)\n",
    "result_df = X_test_subset[['Day', 'Month', 'Year']].copy()\n",
    "result_df['Date'] = pd.to_datetime(X_test_subset[['Day', 'Month', 'Year']])\n",
    "result_df['Sales'] = y_test.head(20)\n",
    "result_df['Predicted Sales']= prediction_final\n",
    "result_df = result_df.sort_values(by='Date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs predicted sales\n",
    "plt.figure(figsize=(19,8))\n",
    "plt.plot(result_df['Date'], result_df['Sales'], label='Actual Sales', marker='o')\n",
    "plt.plot(result_df['Date'], result_df['Predicted Sales'], label='Predicted Sales', marker='o')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Actual Sales VS Predicted Sales' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
